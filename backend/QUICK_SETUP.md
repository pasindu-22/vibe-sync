# Quick Setup Guide

## ğŸš€ Step-by-Step Backend Setup

### Prerequisites
- Python 3.8 or higher installed
- Git (optional, for cloning)
- At least 4GB free disk space (for model files)

### Step 1: Navigate to Backend Directory
```bash
cd "<path_to_Vibe-Sync>\Vibe-Sync\vibe-sync\backend"
```

### Step 2: Run Initial Setup
```bash
setup.bat
```

**What this does:**
- Creates Python virtual environment (`venv/`)
- Installs all required dependencies

### Step 3: Generate Model Files (If Needed)

If you see "âš ï¸ Model files not found" message:

#### Option A: Run Jupyter Notebook (Recommended)
```bash
# Activate virtual environment first
venv\Scripts\activate.bat

# Install Jupyter if not already installed
pip install jupyter

# Start Jupyter notebook
jupyter notebook app/notebook/music-genre-classification.ipynb
```

Then in the notebook:
1. Run all cells (Cell â†’ Run All)
2. Wait for training to complete (~30-60 minutes)
3. Model files will be saved automatically

#### Option B: Download Pre-trained Models
If you have pre-trained model files:
1. Place `efficientnet_music_genre_model.h5` in `app/cnn-models/`
2. Place `label_encoder.pkl` in `app/cnn-models/`

### Step 4: Start the Server
```bash
start_server.bat
```

**Server will be available at:**
- ğŸ“š API Documentation: http://localhost:8000/docs
- ğŸ” Health Check: http://localhost:8000/api/health/classification


## ğŸ¯ Quick Commands Reference

### Daily Startup (After Initial Setup)
```bash
# Navigate to backend directory
cd "<path_to_Vibe-Sync>\Vibe-Sync\vibe-sync\backend"

# Start server
start_server.bat
```

### Manual Server Start
```bash
# Activate virtual environment
venv\Scripts\activate.bat

# Start server manually
uvicorn app.main:app --reload --host localhost --port 8000
```

### Troubleshooting Commands
```bash
# Reinstall dependencies
venv\Scripts\activate.bat
pip install -r requirements.txt

# Check virtual environment
venv\Scripts\activate.bat
python --version
pip list

# Check if server is running
curl http://localhost:8000/api/health/
```

## ğŸ“‚ Project Structure

```
backend/
â”œâ”€â”€ setup.bat                    # Initial setup script
â”œâ”€â”€ start_server.bat            # Daily server start script  
â”œâ”€â”€ example_usage.py            # API usage examples
â”œâ”€â”€ venv/                       # Virtual environment 
â””â”€â”€ app/
    â”œâ”€â”€ main.py                 # FastAPI utilities
    â”œâ”€â”€ services/
    â”‚   â””â”€â”€ music_classifier.py # Classification service
    â”œâ”€â”€ routers/
    â”‚   â”œâ”€â”€ music_classification.py  # API endpoints
    â”‚   â””â”€â”€ health.py               # Health checks
    â”œâ”€â”€ config/
    â”‚   â””â”€â”€ music_config.py     # Configuration
    â””â”€â”€ cnn-models/             # Model files
        â”œâ”€â”€ efficientnet_music_genre_model.h5
        â””â”€â”€ label_encoder.pkl
```

## ğŸµ API Endpoints

Once running, visit: **http://localhost:8000/docs**

## ğŸ’¡ How It Works

1. **Audio Processing**: Converts audio to mel spectrograms (224x224 images)
2. **Segmentation**: Divides long tracks into 30-second segments  
3. **Classification**: Uses EfficientNetB0 model for each segment
4. **Voting**: Final genre determined by majority vote across segments
